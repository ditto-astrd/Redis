# 목차 - 레디스로를 캐시로 사용하기
1. 레디스와 캐시
2. 캐싱 전략
   (1) 읽기 전략 - look aside
   (2) 쓰기 전략과 캐시의 일관성
3. 캐시에서의 데이터 흐름
   (1) Redis에서 만료시간 설정
   (2) 메모리 관리와 maxmemory-policy 설정
   (3) 캐시 스탬피드 현상
4. 세션 스토어로서의 레디스
5. Cache vs Session

<br/>

## 1. 레디스와 캐시
- DB의 테이블에 접근시 데이터를 가져오는 과정에서 CPU와 메모리 등의 리소스를 많이 사용했다면, 캐시를 사용함으로 어플리케이션 자체의 리소스를 줄일 수 있다. 
- 나아가 DB에 장애가 발생하더라도 캐시에서 데이터를 가져오는 것으로 장애 시간을 줄일 수 있는 장점이 있다.
- 레디스로 캐시를 사용하면...
	- 인메모리 데이터 저장소의 특징 덕에 데이터의 반환 과정이 빠름
	- 평균 읽기 쓰기 작업 속도가 1ms 미만인데, 이는 초당 수백만 건의 작업이 가능함을 의미
	- 고가용성의 기능으로 인해, 일부 캐싱 전략에서 캐시에 접근할 수 없게 되는 경우 발생하는 장애를 방지할 수 있음
		- 레디스의 센티널, 또는 클러스터 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 Fail Over를 발생시켜 운영자의 개입 없이 캐시가 정상으로 유지됨
	- 클러스터(= 레디스의 자체 샤딩 솔루션)로인해 캐시의 스케일 아웃 또한 쉽게 처리 가능

## 2. 캐싱 전략
### (1) 읽기 전략 - look aside

![look aside](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fz05h9%2FbtrJuRSHDkF%2FZd3WHu7uJTX9fEyVI83QY1%2Fimg.png)
#### Cache Hit
1. 어플리케이션에 데이터가 있는지 먼저 레디스 캐시에서 확인
2. 캐시에 데이터가 있으면 캐시를 읽어옴 (= 캐시 히트)

#### Cache Miss
1. 레디스 캐시에서 찾고자하는 데이터가 없을 때, 직접 DB에 접근해서 데이터를 가져옴
2. 그 뒤 어플리케이션은 이를 다시 캐시에 저장 (= **lazy loading**)

#### 장점
- 레디스에 문제가 생겨 접근할 수 없는 상황이 발생하더라도 DB에서 데이터를 가져올 수 있음 

#### 단점
- 다만 모든 커넥션이 원본 DB로 몰리면 부하로 인해 어플리케이션 성능에 영향이 미칠 수 있음 (133p)
- <span style="color:red"> 레디스에 문제가 생겨서 접근 불가능한 케이스가 뭐지? 센티널이나 클러스터때문에 FailOver가 되는거 아닌가?</span>
- lazy loading으로 인해 신규 서비스에 Redis를 도입하는 상황이라면 되려 성능에 영향이 미칠 수 있음
	- 따라서 이럴 때 미리 DB에서 -> 캐시로 데이터를 밀어주는 작업을 하는데, 이것이 Cache Warming (**캐시 워밍**)

#### 실제 사례
```
[ 공연 예매 > 공연 상세정보 조회시 레디스 캐시를 사용 ]
Lazy Loading으로 인한 DB Connection Pool의 집중을 최소화 하고자, 서비스 오픈 전 DB에 저장된 데이터를 Redis로 밀어넣는 캐시 워밍 작업을 진행
```

### (2) 쓰기 전략과 캐시의 일관성
원본 DB와 레디스 캐시의 데이터가 불일치하는 캐시 불일치 (Cache Inconsistency)를 방지하는 쓰기 전략이 존재한다.

#### Write Through
![Write Through](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FccLqoA%2FbtrJvFxhdOy%2FU9P7jR288OAUkvO48Fi8j1%2Fimg.png)
- DB에 업데이트 할 때 마다 매번 캐시에도 데이터를 함께 업데이트
- 캐시가 항상 최신 데이터를 갖고있다는 장점이 있지만, 2개의 저장소에 저장이 이루어지기 때문에 데이터를 쓸 때 마다 시간이 오래걸릴 수 있음
- 업데이트가 자주 이루어지는 데이터는 되려 캐시로 사용하기에 부적절한 데이터일 수 있음
	- 따라서 Write Through을 사용할 경우, 데이터 저장시 만료 시간을 사용하는 것을 권장

### Cache Validation
- DB에 값을 업데이트 할 때 마다 캐시에서 데이터를 삭제하는 전략
- 저장소에서 특정 데이터를 삭제하는 것이 새로운 데이터를 저장하는 것보다 훨씬 리소스를 적게 사용하기 때문에 앞선 write through의 단점을 보완

### Write Behind (Write Back)
![Write Behind](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzEE9G%2FbtrJrgeWisI%2FwBK1daTgKE1RYC1eVDwa60%2Fimg.png)
- 캐시임에도 불구하고 쓰기가 빈번한 경우에 권장
	- 먼저 레디스 캐시에 데이터를 빠르게 접근할 수 있도록 업데이트를 진행 (선 레디스 캐시)
	- 그런 다음 건수나 특정 시간 간격 등에 따라 비동기적으로 DB에 업데이트 (후 DB)
- 저장되는 데이터가 실시간으로 정확한 데이터가 아니어도 되는 경우 권장

#### 실제 사례
```
[ 유튜브 스트리밍 사이트의 동영상 좋아요 수 ]
- 이걸 누가 좋아요를 누를때마다 관계형 DB에서 UPDATE를 친다면 십중팔구 DB가 죽을 것이다.
- 좋아요를 누른 데이터를 우선 레디스에 저장 -> 5분 간격으로 집계해 DB에 저장
```
#### 단점
- 레디스 캐시에 문제가 생겨 데이터가 날아갈 경우, 집계 간격 동안의 데이터가 날아갈 수 있다는 위험을 감수해야 함

## 3. 캐시에서의 데이터 흐름
- 캐시의 정의는 `데이터 중 사용자가 자주 사용할 만한 데이터를 가져와서 임시로 저장하는 저장소`
- 따라서 데이터 스토어보다 적은 양을 보관하는 데이터 서브셋
- 특히 레디스 자체가 메모리에 모든 데이터를 저장하며, 이는 기본적으로 서버의 스토리지보다 훨씬 적은 양을 보관
- 따라서 캐시는 가득 차지 않게 일정 양의 데이터를 유지해야 하며, 계속해서 새로운 데이터가 저장되고 기존 데이터는 삭제가 될 수 있도록 관리해야 함
- 결론적으로 적절한 시간의 <mark>TTL</mark> 설정은 필수

### (1) Redis에서 만료시간 설정
EXPIRE 키워드로 설정 가능하다.
``` sql
SET a 100
EXPIRE a 60  --- EXPIRE 키워드로 저장된 키의 만료 시간을 설정할 수 있음
```
- INCR 커맨드로 데이터를 조작하거나 RENAME으로 키의 이름을 바꿔도 TTL은 변경되지 않음
- 그러나 신규 value로 덮어씌울 경우, TTL은 유지되지 않고 사라짐

### TTL 이후 일어나는 키 삭제 방식
Redis에서 키가 만료됐다고 바로 메모리에서 삭제되는 것은 아니며, 아래 2가지 방식으로 삭제된다.
```
[ passive 방식 ]
- 사용자가 키에 접근할 때 키가 만료된 상태라면 메모리에서 수동삭제
- 사용자가 접근할 때에만 수동적으로 삭제됨
- 키 만료 후 사용자가 접근하지 않아 삭제되지 못할 수 있음

[ active 방식 ]
- TTL 값이 있는 키 중 20개를 랜덤하게 뽑아 만료된 키를 모두 메모리에서 삭제
- 약 25%이상이 삭제됐다면 다시 20개의 키를 랜덤하게 뽑아서 확인 
- 이 과정을 1초에 10번씩 수행
```
만료된 키를 곧 바로 삭제하지 않기 때문에 삭제하는 데에 들어가는 리소스를 줄일 수 있지만, 그만큼 메모리를 더 사용할 가능성이 존재한다.

### (2) 메모리 관리와 maxmemory-policy 설정
- 레디스의 메모리는 제한적이기 때문에, 모든 키에 만료 시간을 설정하더라도 너무 많은 키가 저장되면 메모리가 가득 차는 상황이 발생할 수 있음
- 메모리의 용량을 초과하는 양의 데이터가 저장되면 레디스는 내부 정책을 사용해 어떤 키를 삭제할지 결정
- `maxmemory` : 데이터의 최대 저장 용량을 설정
- `maxmemory-policy` : `maxmemory`를 초과할 때 처리 방식을 결정하는 설정값

아래 내용을 통해 `maxmemory-policy`의 설정값을 확인해보자.

#### Noeviction
- 레디스의 데이터가 가득차도 임의로 데이터를 삭제하지 않고(active 방식) 데이터를 저장할 수 없다는 에러를 반환
- 관리자가 직접 데이터를 제거해주겠다는 의미로 통함

#### LRU (Least Recently Used) Eviction 
- 가장 최근에 사용되지 않은 데이터부터 삭제하는 정책
- 효율적인 메모리 관리 방법
- 두 가지 방식이 있음
	- Volatile-LRU
		- 만료 시간이 설정돼 있는 키에 한해 LRU 방식으로 키를 삭제
		- 만약 모든 키에 TTL이 적용되어있지 않다면, 이는 Noeviction과 동일함
	- Allkeys-LRU
		- 공식문서에서 권장하는 **레디스를 잘 모르면 사용을 권장하는 Default**
		- 모든 키에 대해 LRU 알고리즘으로 데이터를 삭제
		- Noeviction을 방지할 수 있음

#### LFU Eviction
- 레디스에 데이터가 가득 찼을 때 자주 사용되지 않은 데이터부터 삭제하는 정책
- LRU와 유사하지만 키를 엑세스하는 패턴에 따라 우선순위가 유동적으로 바뀐다는 점에서 특정 케이스는 LRU보다 더 효율적
- ex ) 키가 오랫동안 사용되지 않았더라도 과거에 자주 액세스했던 키라면 나중에라도 자주 사용될 수 있다는 가정하에 우선순위가 높아짐
- 두 가지 방식이 있음
	- Volatile-LFU
		- 마찬가지로 TTL이 설정된 키에 한해서 LFU 방식으로 삭제
		- 마찬가지로 모든 키에 TTL이 적용되어있지 않다면 Noeviction과 동일
	- Allkeys-LFU
		- 모든 키에 대해 LFU 알고리즘으로 삭제

#### LRU Eviction과 LFU Eviction의 공통점
- 근사 알고리즘으로 구현됨
- 일반적으로 Noeviction을 사용하지 않은 이상, 근사 알고리즘이 동작
- 따라서 정확한 키를 계산하기보다는 특정 키를 근사치로 찾아내 효율적인 데이터를 삭제하는 방법으로 작동

#### RANDOM Eviction
- 저장된 키 중 하나를 랜덤으로 골라내 삭제
	- 랜덤이기 때문에 나중에 사용될 수도 있는 데이터를 삭제할 가능성이 높아짐
	- 이 경우 DB에서 다시 데이터를 갖고와 캐시에 저장하는 과정이 필요됨
- 레디스는 근사 알고리즘을 사용하기 때문에 LFU, LRU 모두 큰 리소스를 사용하지 않음
- 따라서 굳이 레디스의 부하를 줄이겠다고 RANDOM Eviction을 사용하는 것은 권장되지 않음
- RANDOM Eviction도 volatile-random과 allkeys-random 방식을 갖고있음 (내용은 위와 동일)

### Volatile-TTL
- 만료시간이 가장 작은 키를 삭제
- LRU, LFU와 동일하게 근사 알고리즘을 사용

### (3) 캐시 스탬피드 현상

모든 키에 대해 만료 시간을 설정하는 것은 권장되지만, 대규모 트래픽 환경에서 만료 시간을 어떻게 설정하느냐에 따라 캐시 스탬피드가 발생할 수 있다.
(* 캐시 스탬피드 : 순간적으로 DB에 동일 데이터를 조회한 뒤, 캐시 시스템에 중복된 쓰기 요청이 몰리는 상황)
```
1. 어플리케이션 1, 어플리케이션 2가 look aside 방식으로 레디스 1개를 사용하고 있음
2. 이때 레디스의 특정 키가 만료되면, 어플리케이션 서버들은 한꺼번에 DB에 가서 데이터를 읽어오는 과정을 거침 = 중복 읽기
3. 이후 각 어플리케이션에서는 읽어온 데이터를 레디스에 쓰게 되는데, 이 또한 여러번 반복되기 때문에 중복 쓰기가 발생 
```

- 일반적으로 정렬, 카운팅처럼 DB에서 쿼리하는데 오래 걸리는 작업은 미리 계산해서 캐시에 저장해두기 때문에, 
  캐시에 데이터가 없는 경우 이 데이터를 다시 DB에 접근해서 계산하는 작업이 필요
- 이 과정에서 캐시 스탬피드가 발생하면 DB의 부하 -> 서비스 이슈로 이어질 수 있음

#### 해결책 1 - 적절한 만료 시간 설정
- 만료 시간을 너무 짧지 않게 설정
- 여러 어플리케이션이 접근하는 경우, 반복적으로 사용돼야 하는 데이터라면 저장 시점부터 만료 시간으 충분히 길게 설정

#### 해결책 2 - 선 계산
- look aside 방식은 보통 아래와 같이 구현됨
``` python
def fetch(key) : 
	value = redis.get(key)
	if (!value):
		value = db.fetch(key)
		redis.set(value)
	return value
```
- 캐시 스탬피드는 데이터 만료 시점에 여러 어플리케이션이 동시다발적으로 이를 인지하고, 이후 작업을 동시에 진행하기 때문
- 따라서 키가 실제로 만료되기 전에 이 값을 미리 갱신해주면 데이터 스탬피드를 미연에 방지 가능
``` python
def fetch(key, expiry_gap):
	ttl = redis.ttl(key)

	if ttl - (random() * expiry_gap) > 0:
		return redis.get(key)
	else:
		value = db.fetch(key)
		redis.set(value, KEY_TTL)
		return value
```
``` sql
fetch('hello', 2)
```
- hello라는 키의 만료 시간이 10초였다면, 10초 후 레디스의 키가 만료돼 DB에 접근해서 새로운 데이터를 가지고 와 레디스에 저장했을 것
- 그러나 랜덤한 확률로 키가 되기 전 데이터를 갱신하도록 로직 변경
- 단순히 생각하면 데이터를 갖고오는 것 보다 더 많은 리소스를 사용한다고 볼 수 있지만, 상황에 따라 `expiry_gap`만 적절히 설정하면 캐시 스탬피드 현상을 줄일 수 있기 때문에 전체적인 성능을 향상시키는 방법


### PER 알고리즘
- 캐시 스탬피드를 완화하고자 2015년에 연구된 개념
- 캐시 값이 만료되기 전에 언제 DB에 접근해서 값을 읽어오면 되는지 최적으로 계산하는 알고리즘
``` text
currentTime - (timeToCompute * beta * log(rand()) ) > expiry

- currentTime : 현재 남은 만료 시간
- timeToCompute : 캐시된 값을 다시 계산하는 데 걸리는 시간
- beta : 기본적으로 1.0보다 큰 값으로 설정 가능
- rand() : 0과 1 사이의 랜덤 값을 반환하는 함수
- expiry : 키를 재설정할 때 새로 넣어줄 만료 시간
```
- 만료 시간이 가까워질수록 `currentTime`과 `expire`사이의 차이가 작아지며, `rand()` 함수가 반환환 무작위 값에 의존하기 때문에 조건이 참이 될 확률이 높아짐
  - 이 말은 즉슨, 만료 시간이 다가올수록 더 자주 만료된 캐시 항목을 확인
  - 이는 불필요한 재계산을 효과적으로 방지하는 방법


## 3. 세션 스토어로서의 레디스
- 세션 : 서비스를 사용하는 클라이언트의 상태 정보를 의미
  - 현재 서비스에 로그인 된 클라이언트가 누구인지, 어떤 활동을 하고있는지 저장
  - 유저가 떠나면 세션 스토어에서 유저 정보를 삭제
  - ex ) 쇼핑몰에서 유저가 어떤 물건을 담고, 최근 본 것이 무엇것인지의 정보를 세션에 저장해두면 로그인 동안 해당 정보가 유지되며, 유저가 각 페이지에서 보낸 시간을 저장한 뒤 이를 분석해 BI에서 비즈니스 개선에 사용될 수 있음
- 유저가 로그인 한 동안 세션의 데이터를 끊임없이 읽고 쓰게 되므로 빠른 응답 속도는 필수적 -> 레디스 사용에 적합
- 트래픽이 거대해질수록 웹 서버가 늘어나고, 이는 서버별 세션 스토어의 개수도 따라서 증가함을 뜻함
  - 유저의 세션 정보를 갖고 있는 웹 서버에 종속되어 관리가 필요되므로, 세션을 어떻게 관리하는지도 중요
  - 세션 관리가 지켜지지 않으면 대충 관리하면 이커머스에서는 서버에 재접속한 유저가 찜 목록에 저장한 아이템이 사라지는 현상이 발생할 수 있음

### 세션 스토어 (Sticky Session) 
![Sticky Session](https://blog.kakaocdn.net/dn/FSzG4/btsf9B55xS8/Y0bZI1GJOb8PszZk8hg3Jk/img.png)
- 유저의 세션 정보를 갖고 있는 웹 서버에 종속되어 관리가 유지될 경우, 웹 서버에 유저가 몰려 트래픽이 집중되는 상황이 발생하더라도, 유저는 다른 서버를 사용할 수 없음
- 결국 트래픽을 분산시킬 수 없는 상황이 발생하는데, 이를 Sticky Session이라 부름
- 유저의 세션 정보를 그냥 모든 웹 서버에 복재하면 되지 않을까? -> all-to-all 방법이라 불름
  - 단, 불필요한 저장 공간을 차지하는 사이드 이펙트 발생
  - 하나의 유저는 하나의 서버에만 접속이 가능하기 때문
  - 또한 그 많은 유저의 세션 정보를 복제하는 과정에서 발생하는 네트워크 트래픽을 고려하면 서버가 다운될수도 있음
- 그렇다면 세션 스토어용 DB를 따로 만들면 어떻까?
  - 트래픽이 집중되어 세션 스토어로 저장된 DB의 응답속도가 느려짐 -> 클라이언트의 응답 속도 저하로 연결됨
- 만약 여기에 Redis를 적용한다면? 아래 Redis로 세션 스토어 사용을 참고하자

### Redis로 세션 스토어 사용
![Redis Session Store](https://blog.kakaocdn.net/dn/bwXPmg/btsA0ayz38u/1HWqQNc3ufFhQgivoigmo0/img.png)
- 유저는 세션 스토어에 구애받지 않고, 어떤 웹 서버에 연결되더라도 동일한 세션 데이터를 조회할 수 있어 트래픽을 효과적으로 분산시킬 수 있음
- 데이터의 일관성 또한 지켜짐
- DB보다 접근성도 좋고 속도도 빠르다
- 이때 세션 데이터는 Redis의 Hash 자료구조를 활용해서 저장
``` sql
HMSET usersession:1 Name Garimoo IP 10:20:104:30 Hits 1
OK

HINCRBY usersession:1 Hits 1
1) "2"
```

### Cache vs Session
![cache-redis](https://lh5.googleusercontent.com/proxy/KMPMdIq1tnIm23_5SsfZhzFs_73J_ICdX2JhYwkiwwdxuOsSco9p4IlejEvBpHcklCO4hU0WNEPYXjEVR_z09stmi8OTLEmPDtDlyh_wdmf38M9WXirIZidpjVaotgNBuzatfxUL4FkSTCA9rhwB5qAl7eXimz7xfjTRljU)
- 캐시는 DB의 완전한 서브셋으로 동작
- 즉, 캐시가 갖고있는 데이터는 모두 DB에 저장돼 있으며, 캐시 내부 데이터가 유실되더라도 해당 데이터는 DB에서 찾을 수 있음
- 따라서 캐시에 저장된 데이터는 여러 어플리케이션에서 함께 사용할 수 있음
  - 여러 어플리케이션이 함께 사용할수록 더 효율적
 

![sessions-redis](https://zuminternet.github.io/images/portal/post/2023-07-07-spring-session/spring-session-8.png)
- 반면 세션 스토어에 저장된 데이터는 여러 사용자간 공유되지 않으며, 특정 사용자의 ID에 한해 유효
- 세션에 저장된 데이터는 (개발자가 의도하지 않은 이상) DB에 저장되지 않음
- 유저가 로그아웃하면 세션은 종료되며, 데이터의 종류에 따라 DB에 영구저장할지를 결정
- 세션 스토어에 장애가 발생하면 내부 데이터의 손실 가능성이 있으므로, 레디스를 캐시로 사용할 때 보다 신중한 운영이 필요
