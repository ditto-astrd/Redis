- (97p) Redis에서 제공하는 커맨드는 어플리케이션 레벨에서도 구현이 가능하지만, Redis 자료구조에 내장된 함수를 이용해 원하는 가능을 사용하면 데이터를 어플리케이션의 메모리 영역으로 가져간 뒤 가공하는 데에 걸리는 시간을 줄일 수 있기 때문에 오히려 더 좋은 성능을 낼 수 있음

### Sorted Set과 리더보드
#### 절대적 리더보드
- 서비스의 모든 유저를 정렬시켜 상위권의 목록만을 표시

#### 상대적 리더보드
- 사용자의 스코어를 기반으로 다른 사용자와 비교해 순위를 결정하는 리더보드
	- ex : 본인의 순위를 알려주는 리더보드, 특정 그룹 내에서 순위를 보여주는 리더보드

##### Sorted Set
- Redis에서 Sorted Set 데이터는 저장될 때부터 정렬되어 들어감
- 만약 유저의 스코어를 Sorted Set의 가중치로 설정하면 스코어 순으로 유저가 정렬되기 때문에 리더보드의 데이터를 읽어오기 위해 매번 데이터를 정렬할 필요가 없음
``` redis 
ZADD daily-score:220817 28 player:286
ZADD daily-score:220817 400 player:234
ZADD daily-score:220817 45 player:101
ZADD daily-score:220817 357 player:24
ZADD daily-score:220817 199 player:143
```
``` redis
ZRANGE daily-score:220817 0 -1 withscores // 오름차순으로 정렬된 데이터를 보여줌
```
- ZRANGE는 스코어가 낮은 순서부터 출력
- 만약 게임의 첫 화면으로 오늘의 상위 스코어 3명의 유저만 출력하고 싶다면 다음과 같이 ZREVRANGE 커맨드를 사용할 수 있음
``` redis
ZREVRANGE daily-score:220817 0 2 withscores
```
- 만약 player:286이 게임을 해서 데이터를 업데이트 해야한다면 다음 커맨드로 쉽게 변경 가능
``` redis
ZADD daily-score:220817 200 player:286
```
- sorted set은 기본적으로 set이기 때문에 데이터는 중복으로 저장되지 않으며, 같은 아이템을 저장하고자 할 때 스코어가 다르면 업데이트가 됨
	- 업데이트 된 데이터에 따라 데이터의 순서도 자동 정렬됨

#### 만약 RDBMS 였다면
- 난제 1 ) 모든 유저의 변경 데이터를 실시간으로 업데이트
- 난제 2 ) 점수별로 데이터를 정렬해서 가져오는 작업 자체가 DB에 부하를 줌
- 난제 3 ) 유저가 증가할수록 계산해야하는 데이터의 크기는 배로 늘어남


### 랭킹 합산
- 주간 리더보드는 매주 월요일에 초기화 되고, 수요일에 데이터를 보여주는 상황이라면 월~수의 누적 스코어를 보여준다고 가정하자
- RDBMS에서는
	- 하나의 테이블에서 일자에 해당하는 데이터를 모두 가져와서 선수별로 합침 (ex : 월, 화, 수의 user1의 데이터를 합치기)
	- 이를 다시 소팅
- Redis에서는
	- ZUNIONSTORE 커맨드를 사용해 간단히 구현 가능
	- 지정한 키에 연결된 각 아이템의 스코어를 합산하는 커맨드
``` redis
ZUNIONSTORE weekly-score:2208-3 3 daily-score:220815 daily-score:220816 daily-score:220817
```

#### Sorted Set을 이용한 최근 검색 기록 (105 ~ 110p)
- 만약 최근 검색 내역을 출력하는 조건이 아래와 같다고 가정하자
	- 유저별로 다른 키워드 노출
	- 검색 내역은 중복 제거
	- 가장 최근 검색한 5개의 키워드만 사용자에게 노출
- 이를 RDBMS에서 구현한다면
``` sql
SELECT * FROM keyword WHERE user_id = 123 ORDER BY reg_date DESC LIMIT 5;
```
- 덤으로 아래와 같은 제약이 생김
	- 데이터를 저장할때 중복 데이터를 UPDATE 처리하는 로직은 별도로 구현해야함
	- 테이블에 데이터가 무기한으로 쌓이는 것을 방지하기 위해 주기적으로 배치 작업을 돌려 오래된 검색 기록을 삭제
	- 데이터를 가져올 때 검색한 시점을 기준으로 소팅을 해야하기 떄문에, 유저와 검색 기록이 많을 수록 성능 이슈 가능성 UP
- Sorted Set은 Set이기 때문에 애초에 저장될 때 부터 중복을 허용하지 않으며, 스코어로 시간을 활용한다면 검색 기록으로 정렬될 수 있음
``` redis
ZADD search-keytword:123 20221106153501 코듀로이 // 데이터 입력
ZREVRANGE search-keyword:123 0 4 withssocre // 최근 상위 검색 단어 5개 출력
```

#### Sorted Set을 이용한 태그 기능 (110 ~ 114p)
- 블로그에 게시글을 작성할 때 태그를 사용할 수 있다
- RDBMS에서는
	- 최소한 2개의 테이블 필요 (태그 테이블, 태그-게시글 테이블)
- Redis에서는 Set을 사용하여 간단히 태그 기능 구현 가능
``` redis
SADD post:47:tags IT REDIS DataStore
SADD post:22:tags IT Python
```
- SMEMBERS 커맨드를 활용해 특정 태그를 갖는 포스트를 쉽게 확인 가능
``` redis
SMEMBERS tag:IT:posts
```
- SINTER 커맨드를 이용하면 SET의 교집합을 확인할 수 있음
``` redis
SINTER tag:IT:posts tag:DataStore:posts
```
- 만약 이를 RDMBS에서 구현한다면
	- group by - having절을 사용하여 DB 자체에 부하를 줄 수 있음
```
SELECT post_id FROM tag_post WHERE tag_id IN (1,3) GROUP BY post_id HAVING COUNT(tag_id) <= 2;
```

#### 랜덤 데이터 추출 (114 ~ 116p)
- 랜덤으로 게임 유저를 맵핑하거나 이벤트에 응모한 유저를 랜덤으로 추출, 또는 가챠에서 랜덤으로 아이템을 뽑는 로직을 구현하는 상황을 가정하자
- RDBMS에서는
	- ORDER BY RAND() 함수를 사용
	- 이 함수는 쿼리의 결과값을 랜덤하게 정렬하지만, 조건 절에 맞는 모든 행을 읽은 뒤, 임시 테이블에 넣어 정렬한 다음 랜덤으로 LIMIT에 해당할때까지 데이터를 추출
	- 데이터가 1만건 이상일 경우 이와 같은 쿼리는 성능이 나빠지게 돼 부하가 많이 갈 수 있음
- Redis에서는
	- RANDOMKEY 커맨드로 O(1)의 시간복잡도로 데이터 추출 가능


### 카운팅 (116 ~ 118p)
#### 좋아요
- 실시간 트래픽이 굉장히 많은 사이트에서 하나의 뉴스 댓글에 좋아요가 1초애 몇만 건이 발생할 수 있음
- RDBMS에서는 
	- 1초에 몇 만건의 좋아요가 특정 행에서 증가되면 DB에 직접적인 영향이 발생
	- 단순히 좋아요 개수는 파악하는게 아닌, 어떤 유저가 어떤 댓글에 좋아요를 눌렀는지의 데이터 또한 처리할 수 있어야 함
- Redis에서는
	- SET을 활용해 구현 가능
``` redis
SADD comment-like:12554 967
```
- 댓글 id를 기준으로 SET을 생성한 다음, 좋아요를 누른 유저의 id를 SET에 저장하면 중복 없이 데이터를 저장할 수 있음
- 각 댓글별 좋아요를 누른 수는 SCARD 커맨드로 확인 가능
```
SCARD comment-like:12554
```

#### 읽지 않은 메시지 수 카운팅 (118 ~ 120p)
- RDBMS에서는
	- 메시지가 도착할 때 마다 관계형 DB에서 업데이트를 하면 부하가 생김
- Redis에서는
	- 인메모리 DB에 일시적으로 저장한 뒤 필요한 시점에 한꺼번에 업데이트하는 방식을 사용해서 DB에 부하를 최소화하고 성능을 향상 시킴
- 중복된 데이터를 고려할 필요 없이 단순히 채널에 새로 추가된 메시지의 개수를 확인하면 됨
- 따라서 사용자의 ID를 키로 사용하고, 채널의 ID를 아이템의 키로 활용해 숫자 형태의 메시지 카운트를 관리하는 방법을 고려할 수 있음
- ID 234인 유저가 4234 채널에서 새로운 메시지를 수신하는 명령어의 예시
``` redis
HINCRBY user:234 channel:4234 1
```
- 이미 전송한 메시지가 삭제됐다면 HINCRBY 명령을 사용해 음수값을 입력함으로써 데이터를 감소시킬 수 있음
``` redis
HINCRBY user:123 channel:3135 -1
```
- hash구조는 객체 구조에서의 카운트를 효과적으로 관리할 수 있는 방법

### DAU 구하기 (120 ~ 122p)
- Daily Active User = 하루동안 방문한 사용자의 수
	- 여러번 방문했다 하더라도 한번으로 카운팅이 되어야 함
- 어플리케이션의 사용자 접근 로그와 같은 접속 로그를 활용해 날마다 배치 처리를 실행하는 방식으로 DAU를 계산할 수 있지만, 이런 방식으로 실시간 데이터는 확인할 수 없음
- Redis에서는
	- 유저 ID를 SET에 저장하는 방법도 고려할 수 있지만, 하루 1,000만명의 유저가 방문하는 큰 서비스라면 키 안에 너무 많은 아이템을 저장하게 될 수 있으며, 이는 곧 성능 저하를 야기할 수 있음 (보통 키 하나당 200 ~ 300만개까지 조정할 것을 권장)
	- 또한 저장되는 데이터가 많을수록 메모리를 많이 차지하게 됨
	- 따라서 **BITMAP**을 이용하면 메모리를 효율적으로 줄이면서 실시간으로 서비스의 DAU를 확인할 수 있음
		- 별개의 자료구조가 존재하는 것은 아니며, String 자료구조에 bit 연산을 할 수 있도록 구현됨
- 키가 20221106인 데이터를 만든 뒤, 유저 id의 bit를 1로 설정하면 됨
- id가 14인 유저가 접근했을때에는 다음과 같이 오프셋 14를 1로 설정
``` redis
	SETBIT uv:20221106 14 1
```
- 해당 일자에 접근한 유저의 수를 확인할 때 BITCOUNT 커맨드를 사용할 수 있음
``` redis
BITCOUNT uv:20221106
```
- 비트맵에서 BITOP 커맨드를 사용하면 AND, OR, XOR, NOT 연산을 할 수 있으며, 레디스 서버에서 바로 계산된 결과를 가져올 수 있어 개별 비트를 가져와 서버에서 처리하는 번거로움을 줄임
- 위와 같은 방법으로 게임에서 출석 이벤트를 진행하기 위해 특정 기간 동안 매일 방문한 사용자를 구하고 싶을 때와 같은 상황도 적용 가능


#### hyperloglog를 이용한 어플리케이션 미터링
- 클라우드 환경에서는 Pay as you go, 즉, 유저가 서비스를 사용한 만큼 지불해야 함
- 미터링 솔루션은 사용자의 서비스 사용 내역을 이용하기 떄문에 대용량 데이터를 처리할 수 있어야 함
- 서비스의 규모에 따라 초당 수천 건 이상의 작업이 발생할 수 있으며, 따라서 미터링 솔루션은 높은 처리량과 낮은 대기시간을 가져야 함
	- ex ) 서버와 클라이언트에서 발생한 로그를 수집하고 인덱싱해서 사용자가 특정 로그를 검색하고 조회할 수 있는 서비스를 클라우드 환경에서 제공
		- 이 경우, 로그를 수집할 때마다 서비스의 API를 호출하고, 하나의 API 호출마다 건별로 과금을 매기는 정책이 있다면 사용자별 API 호출 횟수를 카운팅 해야함
	- 1초에 100개씩 로그가 쌓이는 서버가 존재한다면, 한달이면 2억 6천개가 쌓이며, 서버의 대수만큼 그 수는 급증함
- 따라서 다음 조건을 만족하낟면 Redis의 hyperloglog를 사용하는 것을 고려할 수 있음
	- 집합 내의 유일한 데이터 개수를 카운팅
	- 1% 미만의 오차는 허용 가능
	- 카운팅할 때 사용한 정확한 데이터를 다시 확인하지 않아도 됨
- 일반적으로 중복을 피하기 위해 저장된 데이터를 모두 기억해야 하므로, 저장되는 데이터가 많아질수록 그만큼 많은 메모리를 사용함
- 하지만 저장된 값을 다시 확인하지 않아도 되는 경우(Ex : 로그성 데이터)라서 hyperloglog를 이용할 수 있다면 최소한의 메모리만을 사용해 중복되지 않는 데이터의 개수를 계산할 수 있음
``` redis
PFADD 202211:user:245 49483
```


#### Geospatial Index를 이용한 위치 기반 어플리케이션 개발 (125 ~ 128p)
- 다음과 같은 기능이 필요할 경우, Redis의 GEO 커맨드 사용을 권장
	- 사용자의 현재 위치 파악
	- 사용자의 이동에 따른 실시간 변동 위치 업데이트
	- 사용자의 위치를 기준으로 근처의 장소 검색
- RDMS에서는 
	-  위치 데이터를 처리할 때 데이터를 단순히 저장할 뿐이며, 실제 데이터 가공 및 처리 과정은 저장소 외부에서 이루어져야 함
	- 만약 모든 사용자의 위치를 1초마다 업데이트한다고 가정하면 사용자의 증가에 따른 위치 데이터는 몇 십배로 증가할 수 있음
- Redis에서는 
	- geo 자료 구조를 통해 공간 정보 데이터를 처리할 수 있음
	- 다른 자료구조와 마찬가지로 모든 데이터는 메모리에 저장되며, 공간 데이터를 활용해 연산 역시 메모리에서 빠르게 계산될 수 있어서 다른 저장소보다 위치 데이터를 효율적으로 처리 할 수 있음
	- 그러나 Redis를 사용하면 데이터 저장 뿐 아니라 실시간 위치 연산을 직접 수행할 수 있어, 데이터 이동으로 인한 네트워크 트래픽을 감소시키고 어플리케이션 코드의 복잡성을 감소시킬 수 있으므로 빠른 서비스 응답 속도를 보장
	- 또한 Redis의 GEO 기능을 다른 Redis의 커맨드와 조합해 손쉽게 빠르고 효율적인 서비스를 구현할 수 있음
		- ex ) GEO의 SET과 PUB / SUB 기능을 함께 사용하면 특정 맛집에서 이벤트를 발생시킬 때 해당 지역 근처의 사용자에게 실시간 알림을 보내는 서비스를 간단하게 구축할 수 있음
- 아래 데이터는 내부적으로 SORTED SET 구조로 저장됨
``` redis
GEOADD user 50.07232323232 14.2323241421412 142 // ID가 142인 사용자의 위치 정보를 저장
```
- 만약 호텔 근처의 식당을 찾고자 한다면 호텔의 위도와 경도 값을 가져온 뒤, 다음과 같이 GEOSEARCH 커맨드로 검색해 1km내에 있는 식당을 찾을 수 있음
``` redis
GEOSEARCH restaurant fromlon1at 50.213123123123213123 14.123123123123123123 byradius 1km
```
