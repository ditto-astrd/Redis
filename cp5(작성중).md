# 목차 - 레디스로를 캐시로 사용하기
1. temp 

## 1. 레디스와 캐시
- DB의 테이블에 접근시 데이터를 가져오는 과정에서 CPU와 메모리 등의 리소스를 많이 사용했다면, 캐시를 사용함으로 어플리케이션 자체의 리소스를 줄일 수 있다. 
- 나아가 DB에 장애가 발생하더라도 캐시에서 데이터를 가져오는 것으로 장애 시간을 줄일 수 있는 장점이 있다.
- 레디스로 캐시를 사용하면...
	- 인메모리 데이터 저장소의 특징 덕에 데이터의 반환 과정이 빠름
	- 평균 읽기 쓰기 작업 속도가 1ms 미만인데, 이는 초당 수백만 건의 작업이 가능함을 의미
	- 고가용성의 기능으로 인해, 일부 캐싱 전략에서 캐시에 접근할 수 없게 되는 경우 발생하는 장애를 방지할 수 있음
		- 레디스의 센티널, 또는 클러스터 기능을 사용하면 마스터 노드의 장애를 자동으로 감지해 Fail Over를 발생시켜 운영자의 개입 없이 캐시가 정상으로 유지됨
	- 클러스터(= 레디스의 자체 샤딩 솔루션)로인해 캐시의 스케일 아웃 또한 쉽게 처리 가능

## 2. 캐싱 전략
### (1) 읽기 전략 - look aside

![look aside](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fz05h9%2FbtrJuRSHDkF%2FZd3WHu7uJTX9fEyVI83QY1%2Fimg.png)
#### Cache Hit
1. 어플리케이션에 데이터가 있는지 먼저 레디스 캐시에서 확인
2. 캐시에 데이터가 있으면 캐시를 읽어옴 (= 캐시 히트)

#### Cache Miss
1. 레디스 캐시에서 찾고자하는 데이터가 없을 때, 직접 DB에 접근해서 데이터를 가져옴
2. 그 뒤 어플리케이션은 이를 다시 캐시에 저장 (= **lazy loading**)

#### 장점
- 레디스에 문제가 생겨 접근할 수 없는 상황이 발생하더라도 DB에서 데이터를 가져올 수 있음 

#### 단점
- 다만 모든 커넥션이 원본 DB로 몰리면 부하로 인해 어플리케이션 성능에 영향이 미칠 수 있음 (133p)
- <span style="color:red"> 레디스에 문제가 생겨서 접근 불가능한 케이스가 뭐지? 센티널이나 클러스터때문에 FailOver가 되는거 아닌가?</span>
- lazy loading으로 인해 신규 서비스에 Redis를 도입하는 상황이라면 되려 성능에 영향이 미칠 수 있음
	- 따라서 이럴 때 미리 DB에서 -> 캐시로 데이터를 밀어주는 작업을 하는데, 이것이 Cache Warming (**캐시 워밍**)

#### 실제 사례
```
[ 공연 예매 > 공연 상세정보 조회시 레디스 캐시를 사용 ]
Lazy Loading으로 인한 DB Connection Pool의 집중을 최소화 하고자, 서비스 오픈 전 DB에 저장된 데이터를 Redis로 밀어넣는 캐시 워밍 작업을 진행
```

### (2) 쓰기 전략과 캐시의 일관성
원본 DB와 레디스 캐시의 데이터가 불일치하는 캐시 불일치 (Cache Inconsistency)를 방지하는 쓰기 전략이 존재한다.

#### Write Through
![Write Through](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FccLqoA%2FbtrJvFxhdOy%2FU9P7jR288OAUkvO48Fi8j1%2Fimg.png)
- DB에 업데이트 할 때 마다 매번 캐시에도 데이터를 함께 업데이트
- 캐시가 항상 최신 데이터를 갖고있다는 장점이 있지만, 2개의 저장소에 저장이 이루어지기 때문에 데이터를 쓸 때 마다 시간이 오래걸릴 수 있음
- 업데이트가 자주 이루어지는 데이터는 되려 캐시로 사용하기에 부적절한 데이터일 수 있음
	- 따라서 Write Through을 사용할 경우, 데이터 저장시 만료 시간을 사용하는 것을 권장

### Cache Validation
- DB에 값을 업데이트 할 때 마다 캐시에서 데이터를 삭제하는 전략
- 저장소에서 특정 데이터를 삭제하는 것이 새로운 데이터를 저장하는 것보다 훨씬 리소스를 적게 사용하기 때문에 앞선 write through의 단점을 보완

### Write Behind (Write Back)
![Write Behind](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FzEE9G%2FbtrJrgeWisI%2FwBK1daTgKE1RYC1eVDwa60%2Fimg.png)
- 캐시임에도 불구하고 쓰기가 빈번한 경우에 권장
	- 먼저 레디스 캐시에 데이터를 빠르게 접근할 수 있도록 업데이트를 진행 (선 레디스 캐시)
	- 그런 다음 건수나 특정 시간 간격 등에 따라 비동기적으로 DB에 업데이트 (후 DB)
- 저장되는 데이터가 실시간으로 정확한 데이터가 아니어도 되는 경우 권장

#### 실제 사례
```
[ 유튜브 스트리밍 사이트의 동영상 좋아요 수 ]
- 이걸 누가 좋아요를 누를때마다 관계형 DB에서 UPDATE를 친다면 십중팔구 DB가 죽을 것이다.
- 좋아요를 누른 데이터를 우선 레디스에 저장 -> 5분 간격으로 집계해 DB에 저장
```
#### 단점
- 레디스 캐시에 문제가 생겨 데이터가 날아갈 경우, 집계 간격 동안의 데이터가 날아갈 수 있다는 위험을 감수해야 함

## 3. 캐시에서의 데이터 흐름
- 캐시의 정의는 `데이터 중 사용자가 자주 사용할 만한 데이터를 가져와서 임시로 저장하는 저장소`
- 따라서 데이터 스토어보다 적은 양을 보관하는 데이터 서브셋
- 특히 레디스 자체가 메모리에 모든 데이터를 저장하며, 이는 기본적으로 서버의 스토리지보다 훨씬 적은 양을 보관
- 따라서 캐시는 가득 차지 않게 일정 양의 데이터를 유지해야 하며, 계속해서 새로운 데이터가 저장되고 기존 데이터는 삭제가 될 수 있도록 관리해야 함
- 결론적으로 적절한 시간의 <mark>TTL</mark> 설정은 필수

### (1) Redis에서 만료시간 설정
EXPIRE 키워드로 설정 가능하다.
``` sql
SET a 100
EXPIRE a 60  --- EXPIRE 키워드로 저장된 키의 만료 시간을 설정할 수 있음
```
- INCR 커맨드로 데이터를 조작하거나 RENAME으로 키의 이름을 바꿔도 TTL은 변경되지 않음
- 그러나 신규 value로 덮어씌울 경우, TTL은 유지되지 않고 사라짐

### TTL 이후 일어나는 키 삭제 방식
Redis에서 키가 만료됐다고 바로 메모리에서 삭제되는 것은 아니며, 아래 2가지 방식으로 삭제된다.
```
[ passive 방식 ]
- 사용자가 키에 접근할 때 키가 만료된 상태라면 메모리에서 수동삭제
- 사용자가 접근할 때에만 수동적으로 삭제됨
- 키 만료 후 사용자가 접근하지 않아 삭제되지 못할 수 있음

[ active 방식 ]
- TTL 값이 있는 키 중 20개를 랜덤하게 뽑아 만료된 키를 모두 메모리에서 삭제
- 약 25%이상이 삭제됐다면 다시 20개의 키를 랜덤하게 뽑아서 확인 
- 이 과정을 1초에 10번씩 수행
```
만료된 키를 곧 바로 삭제하지 않기 때문에 삭제하는 데에 들어가는 리소스를 줄일 수 있지만, 그만큼 메모리를 더 사용할 가능성이 존재한다.

### (2) 메모리 관리와 maxmemory-policy 설정
- 레디스의 메모리는 제한적이기 때문에, 모든 키에 만료 시간을 설정하더라도 너무 많은 키가 저장되면 메모리가 가득 차는 상황이 발생할 수 있음
- 메모리의 용량을 초과하는 양의 데이터가 저장되면 레디스는 내부 정책을 사용해 어떤 키를 삭제할지 결정
- `maxmemory` : 데이터의 최대 저장 용량을 설정
- `maxmemory-policy` : `maxmemory`를 초과할 때 처리 방식을 결정하는 설정값

아래 내용을 통해 `maxmemory-policy`의 설정값을 확인해보자.

#### Noeviction
- 레디스의 데이터가 가득차도 임의로 데이터를 삭제하지 않고(active 방식) 데이터를 저장할 수 없다는 에러를 반환
- 관리자가 직접 데이터를 제거해주겠다는 의미로 통함

#### LRU (Least Recently Used) Eviction 
- 가장 최근에 사용되지 않은 데이터부터 삭제하는 정책
- 효율적인 메모리 관리 방법
- 두 가지 방식이 있음
	- Volatile-LRU
		- 만료 시간이 설정돼 있는 키에 한해 LRU 방식으로 키를 삭제
		- 만약 모든 키에 TTL이 적용되어있지 않다면, 이는 Noeviction과 동일함
	- Allkeys-LRU
		- 공식문서에서 권장하는 **레디스를 잘 모르면 사용을 권장하는 Default**
		- 모든 키에 대해 LRU 알고리즘으로 데이터를 삭제
		- Noeviction을 방지할 수 있음

#### LFU Eviction
- 레디스에 데이터가 가득 찼을 때 자주 사용되지 않은 데이터부터 삭제하는 정책
- LRU와 유사하지만 키를 엑세스하는 패턴에 따라 우선순위가 유동적으로 바뀐다는 점에서 특정 케이스는 LRU보다 더 효율적
- ex ) 키가 오랫동안 사용되지 않았더라도 과거에 자주 액세스했던 키라면 나중에라도 자주 사용될 수 있다는 가정하에 우선순위가 높아짐
- 두 가지 방식이 있음
	- Volatile-LFU
		- 마찬가지로 TTL이 설정된 키에 한해서 LFU 방식으로 삭제
		- 마찬가지로 모든 키에 TTL이 적용되어있지 않다면 Noeviction과 동일
	- Allkeys-LFU
		- 모든 키에 대해 LFU 알고리즘으로 삭제

#### LRU Eviction과 LFU Eviction의 공통점
- 근사 알고리즘으로 구현됨
- 일반적으로 Noeviction을 사용하지 않은 이상, 근사 알고리즘이 동작
- 따라서 정확한 키를 계산하기보다는 특정 키를 근사치로 찾아내 효율적인 데이터를 삭제하는 방법으로 작동

#### RANDOM Eviction
- 저장된 키 중 하나를 랜덤으로 골라내 삭제
	- 랜덤이기 때문에 나중에 사용될 수도 있는 데이터를 삭제할 가능성이 높아짐
	- 이 경우 DB에서 다시 데이터를 갖고와 캐시에 저장하는 과정이 필요됨
- 레디스는 근사 알고리즘을 사용하기 때문에 LFU, LRU 모두 큰 리소스를 사용하지 않음
- 따라서 굳이 레디스의 부하를 줄이겠다고 RANDOM Eviction을 사용하는 것은 권장되지 않음
- RANDOM Eviction도 volatile-random과 allkeys-random 방식을 갖고있음 (내용은 위와 동일)

### Volatile-TTL
- 만료시간이 가장 작은 키를 삭제
- LRU, LFU와 동일하게 근사 알고리즘을 사용

### (3) 캐시 스탬피드 현상

모든 키에 대해 만료 시간을 설정하는 것은 권장되지만, 대규모 트래픽 환경에서 만료 시간을 어떻게 설정하느냐에 따라 캐시 스탬피드가 발생할 수 있다.
(* 캐시 스탬피드 : 순간적으로 DB에 동일 데이터를 조회한 뒤, 캐시 시스템에 중복된 쓰기 요청이 몰리는 상황)
```
1. 어플리케이션 1, 어플리케이션 2가 look aside 방식으로 레디스 1개를 사용하고 있음
2. 이때 레디스의 특정 키가 만료되면, 어플리케이션 서버들은 한꺼번에 DB에 가서 데이터를 읽어오는 과정을 거침 = 중복 읽기
3. 이후 각 어플리케이션에서는 읽어온 데이터를 레디스에 쓰게 되는데, 이 또한 여러번 반복되기 때문에 중복 쓰기가 발생 
```

- 일반적으로 정렬, 카운팅처럼 DB에서 쿼리하는데 오래 걸리는 작업은 미리 계산해서 캐시에 저장해두기 때문에, 
  캐시에 데이터가 없는 경우 이 데이터를 다시 DB에 접근해서 계산하는 작업이 필요
- 이 과정에서 캐시 스탬피드가 발생하면 DB의 부하 -> 서비스 이슈로 이어질 수 있음

#### 해결책 1 - 적절한 만료 시간 설정
- 만료 시간을 너무 짧지 않게 설정
- 여러 어플리케이션이 접근하는 경우, 반복적으로 사용돼야 하는 데이터라면 저장 시점부터 만료 시간으 충분히 길게 설정

#### 해결책 2 - 선 계산
- look aside 방식은 보통 아래와 같이 구현됨
``` python
def fetch(key) : 
	value = redis.get(key)
	if (!value):
		value = db.fetch(key)
		redis.set(value)
	return value
```
- 캐시 스탬피드는 데이터 만료 시점에 여러 어플리케이션이 동시다발적으로 이를 인지하고, 이후 작업을 동시에 진행하기 때문
- 따라서 키가 실제로 만료되기 전에 이 값을 미리 갱신해주면 데이터 스탬피드를 미연에 방지 가능
